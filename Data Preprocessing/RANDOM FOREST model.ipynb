{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08ac282",
   "metadata": {},
   "source": [
    "# Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b46b047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_data</th>\n",
       "      <th>word_token</th>\n",
       "      <th>sent_token</th>\n",
       "      <th>subword_token</th>\n",
       "      <th>char_data</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewer mention watch 1 Oz episode youll ...</td>\n",
       "      <td>['One', 'reviewer', 'mention', 'watch', '1', '...</td>\n",
       "      <td>['One reviewer mention watch 1 Oz episode youl...</td>\n",
       "      <td>['One', 'Ġreviewer', 'Ġmention', 'Ġwatch', 'Ġ1...</td>\n",
       "      <td>['O', 'n', 'e', ' ', 'r', 'e', 'v', 'i', 'e', ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>not sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production. filming technique...</td>\n",
       "      <td>['wonderful', 'little', 'production', '.', 'fi...</td>\n",
       "      <td>['wonderful little production.', 'filming tech...</td>\n",
       "      <td>['w', 'onder', 'ful', 'Ġlittle', 'Ġproduction'...</td>\n",
       "      <td>['w', 'o', 'n', 'd', 'e', 'r', 'f', 'u', 'l', ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>not sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie groundbreaking experience! Ive never see...</td>\n",
       "      <td>['movie', 'groundbreaking', 'experience', '!',...</td>\n",
       "      <td>['movie groundbreaking experience!', 'Ive neve...</td>\n",
       "      <td>['movie', 'Ġground', 'breaking', 'Ġexperience'...</td>\n",
       "      <td>['m', 'o', 'v', 'i', 'e', ' ', 'g', 'r', 'o', ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>['think', 'wonderful', 'way', 'spend', 'time',...</td>\n",
       "      <td>['think wonderful way spend time hot summer we...</td>\n",
       "      <td>['think', 'Ġwonderful', 'Ġway', 'Ġspend', 'Ġti...</td>\n",
       "      <td>['t', 'h', 'i', 'n', 'k', ' ', 'w', 'o', 'n', ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>not sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basically there family little boy Jake think t...</td>\n",
       "      <td>['Basically', 'there', 'family', 'little', 'bo...</td>\n",
       "      <td>['Basically there family little boy Jake think...</td>\n",
       "      <td>['B', 'as', 'ically', 'Ġthere', 'Ġfamily', 'Ġl...</td>\n",
       "      <td>['B', 'a', 's', 'i', 'c', 'a', 'l', 'l', 'y', ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>movie idea character development muscle less b...</td>\n",
       "      <td>['movie', 'idea', 'character', 'development', ...</td>\n",
       "      <td>['movie idea character development muscle less...</td>\n",
       "      <td>['movie', 'Ġidea', 'Ġcharacter', 'Ġdevelopment...</td>\n",
       "      <td>['m', 'o', 'v', 'i', 'e', ' ', 'i', 'd', 'e', ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>guess run budget decent script.</td>\n",
       "      <td>['guess', 'run', 'budget', 'decent', 'script',...</td>\n",
       "      <td>['guess run budget decent script.']</td>\n",
       "      <td>['gu', 'ess', 'Ġrun', 'Ġbudget', 'Ġdecent', 'Ġ...</td>\n",
       "      <td>['g', 'u', 'e', 's', 's', ' ', 'r', 'u', 'n', ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>need plot explosion every five minutes?</td>\n",
       "      <td>['need', 'plot', 'explosion', 'every', 'five',...</td>\n",
       "      <td>['need plot explosion every five minutes?']</td>\n",
       "      <td>['need', 'Ġplot', 'Ġexplosion', 'Ġevery', 'Ġfi...</td>\n",
       "      <td>['n', 'e', 'e', 'd', ' ', 'p', 'l', 'o', 't', ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>award generic action movie ever made?</td>\n",
       "      <td>['award', 'generic', 'action', 'movie', 'ever'...</td>\n",
       "      <td>['award generic action movie ever made?']</td>\n",
       "      <td>['aw', 'ard', 'Ġgeneric', 'Ġaction', 'Ġmovie',...</td>\n",
       "      <td>['a', 'w', 'a', 'r', 'd', ' ', 'g', 'e', 'n', ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>Two hour nonstop mindnumbing action.</td>\n",
       "      <td>['Two', 'hour', 'nonstop', 'mindnumbing', 'act...</td>\n",
       "      <td>['Two hour nonstop mindnumbing action.']</td>\n",
       "      <td>['T', 'w', 'o', 'Ġhour', 'Ġnon', 'stop', 'Ġmin...</td>\n",
       "      <td>['T', 'w', 'o', ' ', 'h', 'o', 'u', 'r', ' ', ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sarcastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_data  \\\n",
       "0     One reviewer mention watch 1 Oz episode youll ...   \n",
       "1     wonderful little production. filming technique...   \n",
       "2     movie groundbreaking experience! Ive never see...   \n",
       "3     think wonderful way spend time hot summer week...   \n",
       "4     Basically there family little boy Jake think t...   \n",
       "...                                                 ...   \n",
       "6492  movie idea character development muscle less b...   \n",
       "6493                    guess run budget decent script.   \n",
       "6494            need plot explosion every five minutes?   \n",
       "6495              award generic action movie ever made?   \n",
       "6496               Two hour nonstop mindnumbing action.   \n",
       "\n",
       "                                             word_token  \\\n",
       "0     ['One', 'reviewer', 'mention', 'watch', '1', '...   \n",
       "1     ['wonderful', 'little', 'production', '.', 'fi...   \n",
       "2     ['movie', 'groundbreaking', 'experience', '!',...   \n",
       "3     ['think', 'wonderful', 'way', 'spend', 'time',...   \n",
       "4     ['Basically', 'there', 'family', 'little', 'bo...   \n",
       "...                                                 ...   \n",
       "6492  ['movie', 'idea', 'character', 'development', ...   \n",
       "6493  ['guess', 'run', 'budget', 'decent', 'script',...   \n",
       "6494  ['need', 'plot', 'explosion', 'every', 'five',...   \n",
       "6495  ['award', 'generic', 'action', 'movie', 'ever'...   \n",
       "6496  ['Two', 'hour', 'nonstop', 'mindnumbing', 'act...   \n",
       "\n",
       "                                             sent_token  \\\n",
       "0     ['One reviewer mention watch 1 Oz episode youl...   \n",
       "1     ['wonderful little production.', 'filming tech...   \n",
       "2     ['movie groundbreaking experience!', 'Ive neve...   \n",
       "3     ['think wonderful way spend time hot summer we...   \n",
       "4     ['Basically there family little boy Jake think...   \n",
       "...                                                 ...   \n",
       "6492  ['movie idea character development muscle less...   \n",
       "6493                ['guess run budget decent script.']   \n",
       "6494        ['need plot explosion every five minutes?']   \n",
       "6495          ['award generic action movie ever made?']   \n",
       "6496           ['Two hour nonstop mindnumbing action.']   \n",
       "\n",
       "                                          subword_token  \\\n",
       "0     ['One', 'Ġreviewer', 'Ġmention', 'Ġwatch', 'Ġ1...   \n",
       "1     ['w', 'onder', 'ful', 'Ġlittle', 'Ġproduction'...   \n",
       "2     ['movie', 'Ġground', 'breaking', 'Ġexperience'...   \n",
       "3     ['think', 'Ġwonderful', 'Ġway', 'Ġspend', 'Ġti...   \n",
       "4     ['B', 'as', 'ically', 'Ġthere', 'Ġfamily', 'Ġl...   \n",
       "...                                                 ...   \n",
       "6492  ['movie', 'Ġidea', 'Ġcharacter', 'Ġdevelopment...   \n",
       "6493  ['gu', 'ess', 'Ġrun', 'Ġbudget', 'Ġdecent', 'Ġ...   \n",
       "6494  ['need', 'Ġplot', 'Ġexplosion', 'Ġevery', 'Ġfi...   \n",
       "6495  ['aw', 'ard', 'Ġgeneric', 'Ġaction', 'Ġmovie',...   \n",
       "6496  ['T', 'w', 'o', 'Ġhour', 'Ġnon', 'stop', 'Ġmin...   \n",
       "\n",
       "                                              char_data Sentiment  \\\n",
       "0     ['O', 'n', 'e', ' ', 'r', 'e', 'v', 'i', 'e', ...  positive   \n",
       "1     ['w', 'o', 'n', 'd', 'e', 'r', 'f', 'u', 'l', ...  positive   \n",
       "2     ['m', 'o', 'v', 'i', 'e', ' ', 'g', 'r', 'o', ...  positive   \n",
       "3     ['t', 'h', 'i', 'n', 'k', ' ', 'w', 'o', 'n', ...  positive   \n",
       "4     ['B', 'a', 's', 'i', 'c', 'a', 'l', 'l', 'y', ...  negative   \n",
       "...                                                 ...       ...   \n",
       "6492  ['m', 'o', 'v', 'i', 'e', ' ', 'i', 'd', 'e', ...  negative   \n",
       "6493  ['g', 'u', 'e', 's', 's', ' ', 'r', 'u', 'n', ...  negative   \n",
       "6494  ['n', 'e', 'e', 'd', ' ', 'p', 'l', 'o', 't', ...  negative   \n",
       "6495  ['a', 'w', 'a', 'r', 'd', ' ', 'g', 'e', 'n', ...  negative   \n",
       "6496  ['T', 'w', 'o', ' ', 'h', 'o', 'u', 'r', ' ', ...  negative   \n",
       "\n",
       "            Sarcasm  \n",
       "0     not sarcastic  \n",
       "1     not sarcastic  \n",
       "2         sarcastic  \n",
       "3     not sarcastic  \n",
       "4         sarcastic  \n",
       "...             ...  \n",
       "6492      sarcastic  \n",
       "6493      sarcastic  \n",
       "6494      sarcastic  \n",
       "6495      sarcastic  \n",
       "6496      sarcastic  \n",
       "\n",
       "[6497 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('tokenized Dataset.xlsx')\n",
    "\n",
    "# Define the feature and target columns\n",
    "X = ['word_token', 'sent_token', 'subword_token', 'char_data']\n",
    "Y = 'Sarcasm'\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a756dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[X],\n",
    "    data[Y],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d688c5c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for word_token:\n",
      "\n",
      "Accuracy: 0.83\n",
      "Confusion Matrix:\n",
      "[[545  59]\n",
      " [160 536]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not sarcastic       0.77      0.90      0.83       604\n",
      "    sarcastic       0.90      0.77      0.83       696\n",
      "\n",
      "     accuracy                           0.83      1300\n",
      "    macro avg       0.84      0.84      0.83      1300\n",
      " weighted avg       0.84      0.83      0.83      1300\n",
      "\n",
      "Evaluation for sent_token:\n",
      "\n",
      "Accuracy: 0.83\n",
      "Confusion Matrix:\n",
      "[[539  65]\n",
      " [157 539]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not sarcastic       0.77      0.89      0.83       604\n",
      "    sarcastic       0.89      0.77      0.83       696\n",
      "\n",
      "     accuracy                           0.83      1300\n",
      "    macro avg       0.83      0.83      0.83      1300\n",
      " weighted avg       0.84      0.83      0.83      1300\n",
      "\n",
      "Evaluation for subword_token:\n",
      "\n",
      "Accuracy: 0.83\n",
      "Confusion Matrix:\n",
      "[[545  59]\n",
      " [162 534]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not sarcastic       0.77      0.90      0.83       604\n",
      "    sarcastic       0.90      0.77      0.83       696\n",
      "\n",
      "     accuracy                           0.83      1300\n",
      "    macro avg       0.84      0.83      0.83      1300\n",
      " weighted avg       0.84      0.83      0.83      1300\n",
      "\n",
      "Evaluation for char_data:\n",
      "\n",
      "Accuracy: 0.54\n",
      "Confusion Matrix:\n",
      "[[  1 603]\n",
      " [  0 696]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "not sarcastic       1.00      0.00      0.00       604\n",
      "    sarcastic       0.54      1.00      0.70       696\n",
      "\n",
      "     accuracy                           0.54      1300\n",
      "    macro avg       0.77      0.50      0.35      1300\n",
      " weighted avg       0.75      0.54      0.38      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to vectorize reviews\n",
    "def vectorize_reviews(reviews, vectorizer=None):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorized_reviews = vectorizer.fit_transform(reviews)\n",
    "    else:\n",
    "        vectorized_reviews = vectorizer.transform(reviews)\n",
    "    return vectorized_reviews, vectorizer\n",
    "\n",
    "# Evaluate each tokenization method\n",
    "# Evaluate each tokenization method\n",
    "def train_and_evaluate(tokenized_column):\n",
    "    X_train_tokenized, vectorizer = vectorize_reviews(X_train[tokenized_column])\n",
    "    X_test_tokenized = vectorize_reviews(X_test[tokenized_column], vectorizer)[0]\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_tokenized, y_train)\n",
    "    y_pred = model.predict(X_test_tokenized)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(f\"Evaluation for {tokenized_column}:\\n\")\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "# Evaluate each tokenization method\n",
    "for token_column in X_train.columns:\n",
    "    train_and_evaluate(token_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e80e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376dda93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
