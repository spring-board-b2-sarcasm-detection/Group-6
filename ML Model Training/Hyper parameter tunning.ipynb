{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284afe9a",
   "metadata": {},
   "source": [
    "# Hyper parameter tunning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecbcaed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "416b0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb462892",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_excel('train_data.xlsx')\n",
    "train = Train[['idf_vector', 'Sarcasm']]\n",
    "\n",
    "#X_train = train['idf_vector']\n",
    "#y_train = train['Sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bb64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_excel('test_data.xlsx')\n",
    "test = Test[['idf_vector', 'Sarcasm']]\n",
    "#X_test = test['idf_vector']\n",
    "#y_test = test['Sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99fa234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the array to a file\n",
    "with open('train.pkl', 'wb') as file:\n",
    "    pickle.dump(train, file)\n",
    "# Save the array to a file\n",
    "with open('test.pkl', 'wb') as file:\n",
    "    pickle.dump(test, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5365074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from pickle\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    train_pk = pickle.load(file)\n",
    "\n",
    "# Load test data from pickle\n",
    "with open('test.pkl', 'rb') as file:\n",
    "    test_pk = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f27b6f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_vector</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.35064284 0.         0.70874616 0.35064284 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.36828071 0.         0.74407735 0.36828071 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.33881107 0.00515968 0.68165561 0.33881107 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.3352069  0.         0.68956848 0.3352069  0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.32067146 0.         0.7215108  0.32067146 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>[0.33714827 0.         0.73559621 0.33714827 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>[0.30734299 0.         0.68298441 0.30734299 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>[0.29527348 0.         0.68897146 0.29527348 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>[0.31039716 0.         0.74495319 0.31039716 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>[0.35299828 0.         0.70760842 0.35299828 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             idf_vector  Sarcasm\n",
       "0     [0.35064284 0.         0.70874616 0.35064284 0...        0\n",
       "1     [0.36828071 0.         0.74407735 0.36828071 0...        1\n",
       "2     [0.33881107 0.00515968 0.68165561 0.33881107 0...        0\n",
       "3     [0.3352069  0.         0.68956848 0.3352069  0...        0\n",
       "4     [0.32067146 0.         0.7215108  0.32067146 0...        1\n",
       "...                                                 ...      ...\n",
       "5192  [0.33714827 0.         0.73559621 0.33714827 0...        1\n",
       "5193  [0.30734299 0.         0.68298441 0.30734299 0...        1\n",
       "5194  [0.29527348 0.         0.68897146 0.29527348 0...        1\n",
       "5195  [0.31039716 0.         0.74495319 0.31039716 0...        1\n",
       "5196  [0.35299828 0.         0.70760842 0.35299828 0...        0\n",
       "\n",
       "[5197 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "158aef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_vector</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.36049631 0.         0.7245443  0.36049631 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.34694305 0.         0.69611009 0.34694305 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.32716079 0.         0.70465401 0.32716079 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.32695773 0.         0.7006237  0.32695773 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.2973631  0.         0.65419881 0.2973631  0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>[0.35472576 0.         0.71249637 0.35472576 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>[0.35571375 0.         0.71469093 0.35571375 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>[0.32585507 0.08336784 0.71688115 0.32585507 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>[0.32020593 0.         0.69863111 0.32020593 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>[0.29275678 0.         0.68309916 0.29275678 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             idf_vector  Sarcasm\n",
       "0     [0.36049631 0.         0.7245443  0.36049631 0...        0\n",
       "1     [0.34694305 0.         0.69611009 0.34694305 0...        0\n",
       "2     [0.32716079 0.         0.70465401 0.32716079 0...        1\n",
       "3     [0.32695773 0.         0.7006237  0.32695773 0...        1\n",
       "4     [0.2973631  0.         0.65419881 0.2973631  0...        0\n",
       "...                                                 ...      ...\n",
       "1295  [0.35472576 0.         0.71249637 0.35472576 0...        0\n",
       "1296  [0.35571375 0.         0.71469093 0.35571375 0...        0\n",
       "1297  [0.32585507 0.08336784 0.71688115 0.32585507 0...        1\n",
       "1298  [0.32020593 0.         0.69863111 0.32020593 0...        1\n",
       "1299  [0.29275678 0.         0.68309916 0.29275678 0...        1\n",
       "\n",
       "[1300 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a68c5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pk['idf_vector'] = train_pk['idf_vector'].apply(lambda x: np.fromstring(x.replace('\\n', '')[1:-1], sep=' '))\n",
    "test_pk['idf_vector'] = test_pk['idf_vector'].apply(lambda x: np.fromstring(x.replace('\\n', '')[1:-1], sep=' '))\n",
    "\n",
    "# Split into X_train and y_train\n",
    "X_train = np.vstack(train_pk['idf_vector'].values)\n",
    "y_train = train_pk['Sarcasm']\n",
    "\n",
    "X_test = np.vstack(test_pk['idf_vector'].values)\n",
    "y_test = test_pk['Sarcasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "230a3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, X_test, y_train, y_test, parameters):\n",
    "    # Perform grid search for hyperparameter tuning\n",
    "    log_reg = LogisticRegression()\n",
    "    grid_search = GridSearchCV(log_reg, parameters, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "    \n",
    "    # Train model with best parameters\n",
    "    lr_model = LogisticRegression(**best_params)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    lr_preds = lr_model.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, lr_preds)\n",
    "    conf_matrix = confusion_matrix(y_test, lr_preds)\n",
    "    class_report = classification_report(y_test, lr_preds)\n",
    "\n",
    "    print(f\"Evaluation for the given vectors:\\n\")\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    return lr_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3850b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "Evaluation for the given vectors:\n",
      "\n",
      "Accuracy: 0.76\n",
      "Confusion Matrix:\n",
      "[[494 110]\n",
      " [207 489]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.76       604\n",
      "           1       0.82      0.70      0.76       696\n",
      "\n",
      "    accuracy                           0.76      1300\n",
      "   macro avg       0.76      0.76      0.76      1300\n",
      "weighted avg       0.76      0.76      0.76      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hyper parameters\n",
    "log_parameters = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [100, 200, 500, 1000]\n",
    "}\n",
    "log_model=logistic_regression(X_train,X_test, y_train, y_test,log_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6642b1b0",
   "metadata": {},
   "source": [
    "Best parameters found: {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}\n",
    "Evaluation for the given vectors:\n",
    "\n",
    "Accuracy: 0.76\n",
    "Confusion Matrix:\n",
    "[[494 110]\n",
    " [207 489]]\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.70      0.82      0.76       604\n",
    "           1       0.82      0.70      0.76       696\n",
    "\n",
    "    accuracy                           0.76      1300\n",
    "   macro avg       0.76      0.76      0.76      1300\n",
    "weighted avg       0.76      0.76      0.76      1300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44b3857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_train, X_test, y_train, y_test, parameters):\n",
    "    # Perform grid search for hyperparameter tuning\n",
    "    svm_model = SVC()\n",
    "    grid_search = GridSearchCV(svm_model, parameters, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "    \n",
    "    # Train model with best parameters\n",
    "    svm_model = SVC(**best_params)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_preds = svm_model.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, svm_preds)\n",
    "    conf_matrix = confusion_matrix(y_test, svm_preds)\n",
    "    class_report = classification_report(y_test, svm_preds)\n",
    "\n",
    "    print(f\"Evaluation for the given vectors:\\n\")\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    return svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba00f4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Evaluation for the given vectors:\n",
      "\n",
      "Accuracy: 0.80\n",
      "Confusion Matrix:\n",
      "[[531  73]\n",
      " [193 503]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80       604\n",
      "           1       0.87      0.72      0.79       696\n",
      "\n",
      "    accuracy                           0.80      1300\n",
      "   macro avg       0.80      0.80      0.80      1300\n",
      "weighted avg       0.81      0.80      0.79      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hyper Parameters\n",
    "svm_parameters = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "model_svm = svm(X_train, X_test, y_train, y_test, svm_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0a41d",
   "metadata": {},
   "source": [
    "Best parameters found: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "Evaluation for the given vectors:\n",
    "\n",
    "Accuracy: 0.80\n",
    "Confusion Matrix:\n",
    "[[531  73]\n",
    " [193 503]]\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.73      0.88      0.80       604\n",
    "           1       0.87      0.72      0.79       696\n",
    "\n",
    "    accuracy                           0.80      1300\n",
    "   macro avg       0.80      0.80      0.80      1300\n",
    "weighted avg       0.81      0.80      0.79      1300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7777232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "696258aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test,parameters):\n",
    "    # Perform grid search for hyperparameter tuning\n",
    "    X_t,_,y_t,_=train_test_split(X_train, y_train, train_size=0.1, random_state=42)\n",
    "    rf_model = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(rf_model, parameters, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_t, y_t)\n",
    "    \n",
    "    # Extract best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "    \n",
    "    # Train model with best parameters\n",
    "    rf_model = RandomForestClassifier(**best_params)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_preds = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, rf_preds)\n",
    "    conf_matrix = confusion_matrix(y_test, rf_preds)\n",
    "    class_report = classification_report(y_test, rf_preds)\n",
    "\n",
    "    print(f\"Evaluation for the given vectors:\\n\")\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebc9d38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Evaluation for the given vectors:\n",
      "\n",
      "Accuracy: 0.80\n",
      "Confusion Matrix:\n",
      "[[506  98]\n",
      " [166 530]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       604\n",
      "           1       0.84      0.76      0.80       696\n",
      "\n",
      "    accuracy                           0.80      1300\n",
      "   macro avg       0.80      0.80      0.80      1300\n",
      "weighted avg       0.80      0.80      0.80      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hyper Parameters\n",
    "rf_parameters = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Assuming X_train, y_train, X_test, and y_test are already defined\n",
    "model_rf = random_forest(X_train, X_test, y_train, y_test,rf_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c330a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d1cd142",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "the Random Forest ML model has better performance than the other model with a bench mark of 80% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03737f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
